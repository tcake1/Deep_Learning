{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 기초 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 학습 전략, 순서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 딥러닝 모델 생성\n",
    "2. 데이터 전처리\n",
    "3. data split\n",
    "4. for문으로 training\n",
    "    1. forward\n",
    "    2. loss\n",
    "    3. backprop\n",
    "    4. update\n",
    "5. evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output feature의 size\n",
    "(n-k+2p)/s + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Layer\n",
    "\n",
    "spatial은 줄여주고 dimension은 늘려줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "low level feature은 색, 라인, 작은 필터이기 때문에 매우 작은 부분밖에 볼 수 없다\n",
    "\n",
    "high level feature은 receptive field가 넓어져서 처음 사진에서 꽤 넓은 부분의 정보를 담고 있다. low level보다 좀더 알아볼 수 있는 패턴이 된다.\n",
    "\n",
    "3 * 3을 두번 통과하면 receptive field가 5가 된다.\n",
    "\n",
    "각 feature마다 우리가 원하는 대로 볼 수 있게 할 순 없다. 그냥 모델이 알아서 feature을 만들어서 알아서 학습한다.\n",
    "\n",
    "deconvolution 중간 필터의 feature을 이용해서 spatial을 늘려 주는 연산\n",
    "\n",
    "zero padding하는 이유 spatial 유지해주고 싶어서\n",
    "mirror padding = reflexion padding 똑같은 정보 복사해서\n",
    "\n",
    "spatial을 유지하는 연산\n",
    "3일땐 1\n",
    "5     2\n",
    "7     3\n",
    "\n",
    "이미지 classification은 spatial을 없애는 것이 필요\n",
    "segmentation은 spatial 정보를 유지하는 것이 필요\n",
    "\n",
    "pooling layer 왜 하냐?\n",
    "spetial을 남기되 크기를 줄이는 것\n",
    "하지만 위치정보를 잃게 됨, 그래서 원상복구하면 찾을 수 없음\n",
    "upsampling을 해야하는 task인 경우에는 위치 정보를 저장해준다음 pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG\n",
    "feature을 잘 뽑아내서 여전히 많이 사용한다. feature extraction할 때 사용\n",
    "항상 fclayer가 있다. fc layer가 있으면 파라미터 엄청 늘어난다.\n",
    "VGG16, 19 모두 많이 사용\n",
    "1x1 conv\n",
    "\n",
    "GoogleNet = Inception Module\n",
    "1x1 conv 나옴 - bottle neck layer에서 사용해서 dimension을 확 줄여줌\n",
    "다양한 receptive field를 줘서\n",
    "문제는 파라미터 수 엄청 늘어남 - 1x1 conv 사용해서 줄여줌\n",
    "layer마다 loss를 줌 - 중간중간마다 시그널이 강하게 주기 위해서\n",
    "\n",
    "ResNet\n",
    "네트워크를 통과할 때마다 input의 정보가 많이 손실된다. 깊게 쌓을 수록 학습이 잘 안되는 문제가 발생한다. 이를 해결하기 위해서 conv 통과하는 값과 기존의 x를 더한 값을 나오게 해서 x에 더하게 되는 값만 예측 하도록 했다.\n",
    "\n",
    "DenseNet\n",
    "앞쪽에 나온 정보를 뒤에다가 계속해서 넘겨준다.\n",
    "ResNet은 +이고 DenseNet은 concat, concat하면 파라미터를 더욱 많이 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropogation through Time(BPTT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 시퀀스마다 나온 output마다 loss가 생기게 된다. 그레디언트는 해당 아웃풋에서 이전으로 흐르고 해당 아웃풋에 해당 되는 임베딩 벡터로 여러 갈래로 그레디언트가 흐른다. 문제가 되는 것은 W(여러 시퀀스를 이어주는 가중치)이다.\n",
    "$$W = \\partial{L_2}+\\partial{L_1}+\\partial{L_0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weakness of RNN \n",
    "### Information loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스퀀스가 흐를 수록 그레디언트가 0으로 수렴하기 때문에 길어질수록 초기 정보를 잃어버린다.  \n",
    "이에 대한 해결책으로 정방향, 역방향 두 방향을 모두 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient vanishing/exploding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이외에도 학습이 불안정하고 느린 단점이 있다. 그리고 계산을 분산으로 처리할 수 없다(CNN처럼).  \n",
    "이에 대한 해결책으로 나온 것이 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 장점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시퀀셜한 데이터 처리 쉬움, output 길이를 무한정으로 생성해낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3개의 gate가 존재\n",
    "    - forget gate: 이전 상태를 얼마나 잊을지\n",
    "    - input gate: 현재 input이 얼마나 중요해서 얼마나 받아들일지\n",
    "    - output gate: 현재 정보를 얼마나 보여줄지\n",
    "- 학습해야하는 matrix가 많아짐\n",
    "- 시그모이드 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- update gate\n",
    "- forget gate\n",
    "- 최근에는 cnn을 이용해서도 시퀀스에 적용하기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input_size, hidden_size는 필수적으로 넣어줘야하는 변수\n",
    "- bidirectional: 역방향도 사용할지\n",
    "- batch_first: input의 shape가 원래는 seq_len, batch순이지만 batch, seq_len으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
